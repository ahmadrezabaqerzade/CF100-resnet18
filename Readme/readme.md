First, I downloaded the CIFAR100 dataset and used it for training and testing. Using the functions I wrote, I set the learning rate to 0.2 and weight_decay parameter to 0.0001, and trained the model for 20 epochs. I repeated this process three more times, each time training the model for 20 epochs with learning rates of 0.1, 0.01, and 0.001, and with a learning rate parameter of 0.0001 in the last stage. I achieved an accuracy of 91% on the training data and an accuracy of approximately 56% on the validation data, which was the same as the downloaded test data. The error on the training data was reduced to 0.313, and the error on the validation data was 1.703.
It can be observed that the training error decreased from a value greater than 4 to 0.313, as shown in the loss curve. However, the test error did not decrease below 1.703. The reason for this could be overfitting or slightly different distributions in the training and test data. To address this issue, using dropout to reduce the number of parameters and prevent overfitting to some extent may be helpful.
In the second stage of training, I added dropout and trained the network for 40 epochs with a learning rate of 0.1 and weight decay of 0.0001 for the first 40 epochs, a learning rate of 0.01 and weight decay of 0.0003 for the next 20 epochs, and a learning rate of 0.001 and weight decay of 0.0005 for the last 20 epochs. However, there was no significant improvement in performance, and the loss on the validation set did not decrease below 1.699. It is likely that the difference in the distribution of training and test data in the CIFAR-100 dataset is the cause of this issue.
